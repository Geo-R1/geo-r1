import os
import json
from tqdm import tqdm
from collections import defaultdict

def iou(box1, box2):
    if not (isinstance(box1, list) and len(box1) == 4 and
            isinstance(box2, list) and len(box2) == 4):
        return 0.0
    box1 = [float(c) for c in box1]
    box2 = [float(c) for c in box2]
    inter_x1 = max(box1[0], box2[0])
    inter_y1 = max(box1[1], box2[1])
    inter_x2 = min(box1[2] - 1, box2[2] - 1)
    inter_y2 = min(box1[3] - 1, box2[3] - 1)
    if inter_x1 < inter_x2 and inter_y1 < inter_y2:
        inter = (inter_x2 - inter_x1 + 1) * (inter_y2 - inter_y1 + 1)
    else:
        inter = 0
    union = (box1[2] - box1[0]) * (box1[3] - box1[1]) + (box2[2] - box2[0]) * (box2[3] - box2[1]) - inter
    if union <= 0:
        return 0.0
    return float(inter) / union

def calculate_accuracies_at_thresholds(results_list, iou_thresholds):
    if not results_list:
        return {thresh: (0.0, 0) for thresh in iou_thresholds}, 0

    total_samples = len(results_list)
    correct_counts = {threshold: 0 for threshold in iou_thresholds}

    for result in results_list:
        gt_box = result.get('ground_truth')
        pred_box = result.get('extracted_answer')
        current_iou = iou(pred_box, gt_box)
        
        for threshold in iou_thresholds:
            if current_iou > threshold:
                correct_counts[threshold] += 1
    
    report = {}
    for threshold, count in correct_counts.items():
        accuracy = (count / total_samples * 100) if total_samples > 0 else 0
        report[threshold] = (accuracy, count)
        
    return report, total_samples

def analyze_by_uniqueness_multi_iou(results_path, original_test_set_path, iou_thresholds):
    print(f"æ­¥éª¤ 1/3: æ­£åœ¨ä»Ž '{os.path.basename(original_test_set_path)}' åŠ è½½ is_unique ä¿¡æ¯...")
    uniqueness_map = {}
    try:
        with open(original_test_set_path, 'r', encoding='utf-8') as f:
            original_data = json.load(f)
        for item in original_data:
            key = (item.get('image'), item.get('problem'))
            uniqueness_map[key] = item.get('is_unique', False)
        print(f"æˆåŠŸæž„å»º is_unique æŸ¥æ‰¾è¡¨ï¼ŒåŒ…å« {len(uniqueness_map)} æ¡è®°å½•ã€‚")
    except Exception as e:
        print(f"âŒ è¯»å–æˆ–è§£æžåŽŸå§‹æµ‹è¯•é›†æ—¶å‡ºé”™: {e}")
        return

    print(f"\næ­¥éª¤ 2/3: æ­£åœ¨ä»Ž '{os.path.basename(results_path)}' åŠ è½½å¹¶åˆ†æžæŽ¨ç†ç»“æžœ...")
    with open(results_path, 'r', encoding='utf-8') as f:
        results_data = json.load(f).get('results', [])

    unique_results = []
    non_unique_results = []
    for result in tqdm(results_data, desc="æ­£åœ¨åˆ†ç»„"):
        key = (result.get('image'), result.get('question'))
        is_unique_flag = uniqueness_map.get(key)
        if is_unique_flag is None:
            continue
        if is_unique_flag:
            unique_results.append(result)
        else:
            non_unique_results.append(result)

    print("\næ­¥éª¤ 3/3: æ­£åœ¨è®¡ç®—ç»Ÿè®¡æ•°æ®å¹¶ç”ŸæˆæŠ¥å‘Š...")
    
    unique_report, total_unique = calculate_accuracies_at_thresholds(unique_results, iou_thresholds)
    non_unique_report, total_non_unique = calculate_accuracies_at_thresholds(non_unique_results, iou_thresholds)
    
    print("\n" + "="*70)
    print("ðŸ“Š æŒ‰ç›®æ ‡å”¯ä¸€æ€§ (is_unique) åˆ’åˆ†çš„å¤šIoUé˜ˆå€¼å‡†ç¡®çŽ‡åˆ†æžæŠ¥å‘Š")
    print("="*70)
    
    print(f"âœ… **å”¯ä¸€ç›®æ ‡ (is_unique = True)** çš„æƒ…å†µ (å…± {total_unique} ä¾‹):")
    for threshold in sorted(iou_thresholds):
        accuracy, correct_count = unique_report[threshold]
        print(f"   - Acc @ IoU > {threshold:.2f} :  {accuracy:.2f}%  ({correct_count} / {total_unique})")
    
    print(f"\nâŒ **éžå”¯ä¸€ç›®æ ‡ (is_unique = False)** çš„æƒ…å†µ (å…± {total_non_unique} ä¾‹):")
    for threshold in sorted(iou_thresholds):
        accuracy, correct_count = non_unique_report[threshold]
        print(f"   - Acc @ IoU > {threshold:.2f} :  {accuracy:.2f}%  ({correct_count} / {total_non_unique})")
        
    print("="*70)


def recalculate_accuracy_at_thresholds(results_path, iou_thresholds):
    if not os.path.exists(results_path):
        print(f"âŒ é”™è¯¯ï¼šç»“æžœæ–‡ä»¶æœªæ‰¾åˆ°: '{results_path}'")
        return

    print(f"ðŸ” æ­£åœ¨åŠ è½½ç»“æžœæ–‡ä»¶: {os.path.basename(results_path)}")
    with open(results_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    all_results = data.get('results', [])

    if not all_results:
        print("âš ï¸ è­¦å‘Šï¼šæ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ° 'results' åˆ—è¡¨ï¼Œæˆ–åˆ—è¡¨ä¸ºç©ºã€‚")
        return

    correct_counts = {threshold: 0 for threshold in iou_thresholds}
    total_samples = len(all_results)

    print(f"ðŸ”„ æ­£åœ¨ä¸º {total_samples} æ¡è®°å½•é‡æ–°è®¡ç®— IoU å¹¶ç»Ÿè®¡...")
    for result in all_results:
        gt_box = result.get('ground_truth')
        pred_box = result.get('extracted_answer')

        # è®¡ç®—å½“å‰æ ·æœ¬çš„IoU
        current_iou = iou(pred_box, gt_box)
        
        # ä¸Žæ¯ä¸ªé˜ˆå€¼è¿›è¡Œæ¯”è¾ƒ
        for threshold in iou_thresholds:
            if current_iou > threshold:
                correct_counts[threshold] += 1

    print("\n" + "="*50)
    print("ðŸ“Š å¤š IoU é˜ˆå€¼å‡†ç¡®çŽ‡ (Acc@IoU) åˆ†æžæŠ¥å‘Š")
    print("="*50)
    
    for threshold in sorted(iou_thresholds):
        correct = correct_counts[threshold]
        accuracy = (correct / total_samples * 100) if total_samples > 0 else 0
        print(f"   - Acc @ IoU > {threshold:.2f} :  {accuracy:.2f}%  ({correct} / {total_samples})")
        
    print("="*50)


if __name__ == "__main__":
    # recalculate_acc_unique
    RESULTS_JSON_PATH = '/training/Anonymous/VLM-R1/src/eval/logs_vrsbench_dapo/rec_results_qwen2_5_vl_7b_vrsbench260_grpo.json'
    ORIGINAL_TEST_SET_PATH = '/training/Anonymous/VLM-R1/data/VRSBench/VRSBench_EVAL_referring_detailed_with_unique.json'
    
    IOU_THRESHOLDS_TO_TEST = [0.5, 0.7]

    analyze_by_uniqueness_multi_iou(
        RESULTS_JSON_PATH, 
        ORIGINAL_TEST_SET_PATH,
        IOU_THRESHOLDS_TO_TEST
    )

    # recalculate_acc_multi_thres
    RESULTS_JSON_PATH = '/training/Anonymous/VLM-R1/src/eval/logs_vrsbench_dapo/rec_results_qwen2_5_vl_7b_vrsbench260_grpo.json'
    IOU_THRESHOLDS_TO_TEST = [0.5, 0.7]

    recalculate_accuracy_at_thresholds(RESULTS_JSON_PATH, IOU_THRESHOLDS_TO_TEST)